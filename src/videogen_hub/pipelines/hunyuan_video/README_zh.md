<!-- ## **HunyuanVideo** -->

[English](./README.md)

<p align="center">
  <img src="https://raw.githubusercontent.com/Tencent/HunyuanVideo/refs/heads/main/assets/logo.png"  height=100>
</p>

# HunyuanVideo: A Systematic Framework For Large Video Generation Model

<div align="center">
  <a href="https://github.com/Tencent/HunyuanVideo"><img src="https://img.shields.io/static/v1?label=HunyuanVideo Code&message=Github&color=blue"></a> &ensp;
  <a href="https://aivideo.hunyuan.tencent.com"><img src="https://img.shields.io/static/v1?label=Project%20Page&message=Web&color=green"></a> &ensp;
  <a href="https://video.hunyuan.tencent.com"><img src="https://img.shields.io/static/v1?label=Playground&message=Web&color=green"></a>
</div>
<div align="center">
  <a href="https://arxiv.org/abs/2412.03603"><img src="https://img.shields.io/static/v1?label=Tech Report&message=Arxiv&color=red"></a> &ensp;
  <a href="https://aivideo.hunyuan.tencent.com/hunyuanvideo.pdf"><img src="https://img.shields.io/static/v1?label=Tech Report&message=High-Quality Version (~350M)&color=red"></a>
</div>
<div align="center">
  <a href="https://huggingface.co/tencent/HunyuanVideo"><img src="https://img.shields.io/static/v1?label=HunyuanVideo&message=HuggingFace&color=yellow"></a> &ensp;
  <a href="https://huggingface.co/docs/diffusers/main/api/pipelines/hunyuan_video"><img src="https://img.shields.io/static/v1?label=HunyuanVideo&message=Diffusers&color=yellow"></a> &ensp;
  <a href="https://huggingface.co/tencent/HunyuanVideo-PromptRewrite"><img src="https://img.shields.io/static/v1?label=HunyuanVideo-PromptRewrite&message=HuggingFace&color=yellow"></a>


 [![Replicate](https://replicate.com/zsxkib/hunyuan-video/badge)](https://replicate.com/zsxkib/hunyuan-video)
</div>


<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ <a href="assets/WECHAT.md" target="_blank">WeChat</a> å’Œ <a href="https://discord.gg/GpARqvrh" target="_blank">Discord</a> 
</p>



-----

æœ¬ä»“åº“åŒ…å«äº† HunyuanVideo é¡¹ç›®çš„ PyTorch æ¨¡å‹å®šä¹‰ã€é¢„è®­ç»ƒæƒé‡å’Œæ¨ç†/é‡‡æ ·ä»£ç ã€‚å‚è€ƒæˆ‘ä»¬çš„é¡¹ç›®é¡µé¢ [project page](https://aivideo.hunyuan.tencent.com) æŸ¥çœ‹æ›´å¤šå†…å®¹ã€‚

> [**HunyuanVideo: A Systematic Framework For Large Video Generation Model**](https://arxiv.org/abs/2412.03603) <br>



## ğŸ”¥ğŸ”¥ğŸ”¥ æ›´æ–°!!

* 2025å¹´01æœˆ13æ—¥: ğŸ“ˆ å¼€æº Penguin Video [åŸºå‡†æµ‹è¯•é›†](https://raw.githubusercontent.com/Tencent/HunyuanVideo/refs/heads/main/assets/PenguinVideoBenchmark.csv) ã€‚
* 2024å¹´12æœˆ18æ—¥: ğŸƒâ€â™‚ï¸ å¼€æº HunyuanVideo [FP8 æ¨¡å‹æƒé‡](https://huggingface.co/tencent/HunyuanVideo/blob/main/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt)ï¼ŒèŠ‚çœæ›´å¤š GPU æ˜¾å­˜ã€‚
* 2024å¹´12æœˆ17æ—¥: ğŸ¤— HunyuanVideoå·²ç»é›†æˆåˆ°[Diffusers](https://huggingface.co/docs/diffusers/main/api/pipelines/hunyuan_video)ä¸­ã€‚
* 2024å¹´12æœˆ03æ—¥: ğŸš€ å¼€æº HunyuanVideo å¤šå¡å¹¶è¡Œæ¨ç†ä»£ç ï¼Œç”±[xDiT](https://github.com/xdit-project/xDiT)æä¾›ã€‚
* 2024å¹´12æœˆ03æ—¥: ğŸ‘‹ å¼€æº HunyuanVideo æ–‡ç”Ÿè§†é¢‘çš„æ¨ç†ä»£ç å’Œæ¨¡å‹æƒé‡ã€‚



## ğŸ¥ ä½œå“å±•ç¤º

<div align="center">
  <video width="70%" src="https://github.com/user-attachments/assets/22440764-0d7e-438e-a44d-d0dad1006d3d" poster="./assets/video_poster.png"> </video>
</div>


## ğŸ§© ç¤¾åŒºè´¡çŒ®

å¦‚æœæ‚¨çš„é¡¹ç›®ä¸­æœ‰å¼€å‘æˆ–ä½¿ç”¨ HunyuanVideoï¼Œæ¬¢è¿å‘ŠçŸ¥æˆ‘ä»¬ã€‚

- ComfyUI (æ”¯æŒFP8æ¨ç†ã€V2Vå’ŒIP2Vç”Ÿæˆ): [ComfyUI-HunyuanVideoWrapper](https://github.com/kijai/ComfyUI-HunyuanVideoWrapper) by [Kijai](https://github.com/kijai)

- ComfyUI-Native (ComfyUIå®˜æ–¹åŸç”Ÿæ”¯æŒ): [ComfyUI-HunyuanVideo](https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_video/) by [ComfyUI Official](https://github.com/comfyanonymous/ComfyUI)

- FastVideo (ä¸€è‡´æ€§è’¸é¦æ¨¡å‹): [FastVideo](https://github.com/hao-ai-lab/FastVideo) by [Hao AI Lab](https://hao-ai-lab.github.io/)

- HunyuanVideo-gguf (GGUFã€é‡åŒ–): [HunyuanVideo-gguf](https://huggingface.co/city96/HunyuanVideo-gguf) by [city96](https://huggingface.co/city96)

- Enhance-A-Video (ç”Ÿæˆæ›´é«˜è´¨é‡çš„è§†é¢‘): [Enhance-A-Video](https://github.com/NUS-HPC-AI-Lab/Enhance-A-Video) by [NUS-HPC-AI-Lab](https://ai.comp.nus.edu.sg/)

- TeaCache (åŸºäºç¼“å­˜çš„åŠ é€Ÿé‡‡æ ·): [TeaCache](https://github.com/LiewFeng/TeaCache) by [Feng Liu](https://github.com/LiewFeng)



## ğŸ“‘ å¼€æºè®¡åˆ’

- HunyuanVideo (æ–‡ç”Ÿè§†é¢‘æ¨¡å‹)
  - [x] æ¨ç†ä»£ç 
  - [x] æ¨¡å‹æƒé‡ 
  - [x] å¤šGPUåºåˆ—å¹¶è¡Œæ¨ç†ï¼ˆGPU è¶Šå¤šï¼Œæ¨ç†é€Ÿåº¦è¶Šå¿«ï¼‰
  - [x] Web Demo (Gradio) 
  - [x] Diffusers 
  - [x] FP8 é‡åŒ–ç‰ˆæœ¬
  - [x] Penguin Video åŸºå‡†æµ‹è¯•é›† 
  - [ ] ComfyUI
  - [ ] å¤šGPU PipeFusionå¹¶è¡Œæ¨ç† (æ›´ä½æ˜¾å­˜éœ€æ±‚)
- HunyuanVideo (å›¾ç”Ÿè§†é¢‘æ¨¡å‹)
  - [ ] æ¨ç†ä»£ç  
  - [ ] æ¨¡å‹æƒé‡ 



## ç›®å½•

- [HunyuanVideo: A Systematic Framework For Large Video Generation Model](#hunyuanvideo-a-systematic-framework-for-large-video-generation-model)
  - [ğŸ¥ ä½œå“å±•ç¤º](#-ä½œå“å±•ç¤º)
  - [ğŸ”¥ğŸ”¥ğŸ”¥ æ›´æ–°!!](#-æ›´æ–°)
  - [ğŸ§© ç¤¾åŒºè´¡çŒ®](#-ç¤¾åŒºè´¡çŒ®)
  - [ğŸ“‘ å¼€æºè®¡åˆ’](#-å¼€æºè®¡åˆ’)
  - [ç›®å½•](#ç›®å½•)
  - [**æ‘˜è¦**](#æ‘˜è¦)
  - [**HunyuanVideo çš„æ¶æ„**](#hunyuanvideo-çš„æ¶æ„)
  - [ğŸ‰ **äº®ç‚¹**](#-äº®ç‚¹)
    - [**ç»Ÿä¸€çš„å›¾è§†é¢‘ç”Ÿæˆæ¶æ„**](#ç»Ÿä¸€çš„å›¾è§†é¢‘ç”Ÿæˆæ¶æ„)
    - [**MLLM æ–‡æœ¬ç¼–ç å™¨**](#mllm-æ–‡æœ¬ç¼–ç å™¨)
    - [**3D VAE**](#3d-vae)
    - [**Prompt æ”¹å†™**](#prompt-æ”¹å†™)
  - [ğŸ“ˆ èƒ½åŠ›è¯„ä¼°](#-èƒ½åŠ›è¯„ä¼°)
  - [ğŸ“œ è¿è¡Œé…ç½®](#-è¿è¡Œé…ç½®)
  - [ğŸ› ï¸ å®‰è£…å’Œä¾èµ–](#ï¸-å®‰è£…å’Œä¾èµ–)
    - [Linux å®‰è£…æŒ‡å¼•](#linux-å®‰è£…æŒ‡å¼•)
  - [ğŸ§± ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹](#-ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹)
  - [ğŸ”‘ å•å¡æ¨ç†](#-å•å¡æ¨ç†)
    - [ä½¿ç”¨å‘½ä»¤è¡Œ](#ä½¿ç”¨å‘½ä»¤è¡Œ)
    - [è¿è¡ŒgradioæœåŠ¡](#è¿è¡ŒgradioæœåŠ¡)
    - [æ›´å¤šé…ç½®](#æ›´å¤šé…ç½®)
  - [ğŸš€ ä½¿ç”¨ xDiT å®ç°å¤šå¡å¹¶è¡Œæ¨ç†](#-ä½¿ç”¨-xdit-å®ç°å¤šå¡å¹¶è¡Œæ¨ç†)
    - [ä½¿ç”¨å‘½ä»¤è¡Œ](#ä½¿ç”¨å‘½ä»¤è¡Œ-1)
  - [ğŸš€   FP8 Inference](#---fp8-inference)
    - [Using Command Line](#using-command-line)
  - [ğŸ”— BibTeX](#-bibtex)
  - [è‡´è°¢](#è‡´è°¢)
  - [Star è¶‹åŠ¿](#star-è¶‹åŠ¿)
---



## **æ‘˜è¦**

HunyuanVideo æ˜¯ä¸€ä¸ªå…¨æ–°çš„å¼€æºè§†é¢‘ç”Ÿæˆå¤§æ¨¡å‹ï¼Œå…·æœ‰ä¸é¢†å…ˆçš„é—­æºæ¨¡å‹ç›¸åª²ç¾ç”šè‡³æ›´ä¼˜çš„è§†é¢‘ç”Ÿæˆè¡¨ç°ã€‚ä¸ºäº†è®­ç»ƒ HunyuanVideoï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ä¸ªå…¨é¢çš„æ¡†æ¶ï¼Œé›†æˆäº†æ•°æ®æ•´ç†ã€å›¾åƒ-è§†é¢‘è”åˆæ¨¡å‹è®­ç»ƒå’Œé«˜æ•ˆçš„åŸºç¡€è®¾æ–½ä»¥æ”¯æŒå¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒå’Œæ¨ç†ã€‚æ­¤å¤–ï¼Œé€šè¿‡æœ‰æ•ˆçš„æ¨¡å‹æ¶æ„å’Œæ•°æ®é›†æ‰©å±•ç­–ç•¥ï¼Œæˆ‘ä»¬æˆåŠŸåœ°è®­ç»ƒäº†ä¸€ä¸ªæ‹¥æœ‰è¶…è¿‡ 130 äº¿å‚æ•°çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œä½¿å…¶æˆä¸ºæœ€å¤§çš„å¼€æºè§†é¢‘ç”Ÿæˆæ¨¡å‹ä¹‹ä¸€ã€‚

æˆ‘ä»¬åœ¨æ¨¡å‹ç»“æ„çš„è®¾è®¡ä¸Šåšäº†å¤§é‡çš„å®éªŒä»¥ç¡®ä¿å…¶èƒ½æ‹¥æœ‰é«˜è´¨é‡çš„è§†è§‰æ•ˆæœã€å¤šæ ·çš„è¿åŠ¨ã€æ–‡æœ¬-è§†é¢‘å¯¹é½å’Œç”Ÿæˆç¨³å®šæ€§ã€‚æ ¹æ®ä¸“ä¸šäººå‘˜çš„è¯„ä¼°ç»“æœï¼ŒHunyuanVideo åœ¨ç»¼åˆæŒ‡æ ‡ä¸Šä¼˜äºä»¥å¾€çš„æœ€å…ˆè¿›æ¨¡å‹ï¼ŒåŒ…æ‹¬ Runway Gen-3ã€Luma 1.6 å’Œ 3 ä¸ªä¸­æ–‡ç¤¾åŒºè¡¨ç°æœ€å¥½çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ã€‚**é€šè¿‡å¼€æºåŸºç¡€æ¨¡å‹å’Œåº”ç”¨æ¨¡å‹çš„ä»£ç å’Œæƒé‡ï¼Œæˆ‘ä»¬æ—¨åœ¨å¼¥åˆé—­æºå’Œå¼€æºè§†é¢‘åŸºç¡€æ¨¡å‹ä¹‹é—´çš„å·®è·ï¼Œå¸®åŠ©ç¤¾åŒºä¸­çš„æ¯ä¸ªäººéƒ½èƒ½å¤Ÿå°è¯•è‡ªå·±çš„æƒ³æ³•ï¼Œä¿ƒè¿›æ›´åŠ åŠ¨æ€å’Œæ´»è·ƒçš„è§†é¢‘ç”Ÿæˆç”Ÿæ€ã€‚**



## **HunyuanVideo çš„æ¶æ„**

HunyuanVideo æ˜¯ä¸€ä¸ªéšç©ºé—´æ¨¡å‹ï¼Œè®­ç»ƒæ—¶å®ƒé‡‡ç”¨äº† 3D VAE å‹ç¼©æ—¶é—´ç»´åº¦å’Œç©ºé—´ç»´åº¦çš„ç‰¹å¾ã€‚æ–‡æœ¬æç¤ºé€šè¿‡ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹ç¼–ç åä½œä¸ºæ¡ä»¶è¾“å…¥æ¨¡å‹ï¼Œå¼•å¯¼æ¨¡å‹é€šè¿‡å¯¹é«˜æ–¯å™ªå£°çš„å¤šæ­¥å»å™ªï¼Œè¾“å‡ºä¸€ä¸ªè§†é¢‘çš„éšç©ºé—´è¡¨ç¤ºã€‚æœ€åï¼Œæ¨ç†æ—¶é€šè¿‡ 3D VAE è§£ç å™¨å°†éšç©ºé—´è¡¨ç¤ºè§£ç ä¸ºè§†é¢‘ã€‚
<p align="center">
  <img src="https://raw.githubusercontent.com/Tencent/HunyuanVideo/refs/heads/main/assets/overall.png"  height=300>
</p>


## ğŸ‰ **äº®ç‚¹**

### **ç»Ÿä¸€çš„å›¾è§†é¢‘ç”Ÿæˆæ¶æ„**

HunyuanVideo é‡‡ç”¨äº† Transformer å’Œ Full Attention çš„è®¾è®¡ç”¨äºè§†é¢‘ç”Ÿæˆã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªâ€œåŒæµåˆ°å•æµâ€çš„æ··åˆæ¨¡å‹è®¾è®¡ç”¨äºè§†é¢‘ç”Ÿæˆã€‚åœ¨åŒæµé˜¶æ®µï¼Œè§†é¢‘å’Œæ–‡æœ¬ token é€šè¿‡å¹¶è¡Œçš„ Transformer Block ç‹¬ç«‹å¤„ç†ï¼Œä½¿å¾—æ¯ä¸ªæ¨¡æ€å¯ä»¥å­¦ä¹ é€‚åˆè‡ªå·±çš„è°ƒåˆ¶æœºåˆ¶è€Œä¸ä¼šç›¸äº’å¹²æ‰°ã€‚åœ¨å•æµé˜¶æ®µï¼Œæˆ‘ä»¬å°†è§†é¢‘å’Œæ–‡æœ¬ token è¿æ¥èµ·æ¥å¹¶å°†å®ƒä»¬è¾“å…¥åˆ°åç»­çš„ Transformer Block ä¸­è¿›è¡Œæœ‰æ•ˆçš„å¤šæ¨¡æ€ä¿¡æ¯èåˆã€‚è¿™ç§è®¾è®¡æ•æ‰äº†è§†è§‰å’Œè¯­ä¹‰ä¿¡æ¯ä¹‹é—´çš„å¤æ‚äº¤äº’ï¼Œå¢å¼ºäº†æ•´ä½“æ¨¡å‹æ€§èƒ½ã€‚
<p align="center">
  <img src="https://raw.githubusercontent.com/Tencent/HunyuanVideo/refs/heads/main/assets/backbone.png"  height=350>
</p>

### **MLLM æ–‡æœ¬ç¼–ç å™¨**
è¿‡å»çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹é€šå¸¸ä½¿ç”¨é¢„è®­ç»ƒçš„ CLIP å’Œ T5-XXL ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ï¼Œå…¶ä¸­ CLIP ä½¿ç”¨ Transformer Encoderï¼ŒT5 ä½¿ç”¨ Encoder-Decoder ç»“æ„ã€‚HunyuanVideo ä½¿ç”¨äº†ä¸€ä¸ªé¢„è®­ç»ƒçš„ Multimodal Large Language Model (MLLM) ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ï¼Œå®ƒå…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š
* ä¸ T5 ç›¸æ¯”ï¼ŒMLLM åŸºäºå›¾æ–‡æ•°æ®æŒ‡ä»¤å¾®è°ƒååœ¨ç‰¹å¾ç©ºé—´ä¸­å…·æœ‰æ›´å¥½çš„å›¾åƒ-æ–‡æœ¬å¯¹é½èƒ½åŠ›ï¼Œè¿™å‡è½»äº†æ‰©æ•£æ¨¡å‹ä¸­çš„å›¾æ–‡å¯¹é½çš„éš¾åº¦ï¼›
* ä¸ CLIP ç›¸æ¯”ï¼ŒMLLM åœ¨å›¾åƒçš„ç»†èŠ‚æè¿°å’Œå¤æ‚æ¨ç†æ–¹é¢è¡¨ç°å‡ºæ›´å¼ºçš„èƒ½åŠ›ï¼›
* MLLM å¯ä»¥é€šè¿‡éµå¾ªç³»ç»ŸæŒ‡ä»¤å®ç°é›¶æ ·æœ¬ç”Ÿæˆï¼Œå¸®åŠ©æ–‡æœ¬ç‰¹å¾æ›´å¤šåœ°å…³æ³¨å…³é”®ä¿¡æ¯ã€‚

ç”±äº MLLM æ˜¯åŸºäº Causal Attention çš„ï¼Œè€Œ T5-XXL ä½¿ç”¨äº† Bidirectional Attention ä¸ºæ‰©æ•£æ¨¡å‹æä¾›æ›´å¥½çš„æ–‡æœ¬å¼•å¯¼ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªé¢å¤–çš„ token ä¼˜åŒ–å™¨æ¥å¢å¼ºæ–‡æœ¬ç‰¹å¾ã€‚
<p align="center">
  <img src="https://raw.githubusercontent.com/Tencent/HunyuanVideo/refs/heads/main/assets/text_encoder.png"  height=275>
</p>

### **3D VAE**
æˆ‘ä»¬çš„ VAE é‡‡ç”¨äº† CausalConv3D ä½œä¸º HunyuanVideo çš„ç¼–ç å™¨å’Œè§£ç å™¨ï¼Œç”¨äºå‹ç¼©è§†é¢‘çš„æ—¶é—´ç»´åº¦å’Œç©ºé—´ç»´åº¦ï¼Œå…¶ä¸­æ—¶é—´ç»´åº¦å‹ç¼© 4 å€ï¼Œç©ºé—´ç»´åº¦å‹ç¼© 8 å€ï¼Œå‹ç¼©ä¸º 16 channelsã€‚è¿™æ ·å¯ä»¥æ˜¾è‘—å‡å°‘åç»­ Transformer æ¨¡å‹çš„ token æ•°é‡ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨åŸå§‹åˆ†è¾¨ç‡å’Œå¸§ç‡ä¸‹è®­ç»ƒè§†é¢‘ç”Ÿæˆæ¨¡å‹ã€‚
<p align="center">
  <img src="https://raw.githubusercontent.com/Tencent/HunyuanVideo/refs/heads/main/assets/3dvae.png"  height=150>
</p>

### **Prompt æ”¹å†™**
ä¸ºäº†è§£å†³ç”¨æˆ·è¾“å…¥æ–‡æœ¬æç¤ºçš„å¤šæ ·æ€§å’Œä¸ä¸€è‡´æ€§çš„å›°éš¾ï¼Œæˆ‘ä»¬å¾®è°ƒäº† [Hunyuan-Large model](https://github.com/Tencent/Tencent-Hunyuan-Large) æ¨¡å‹ä½œä¸ºæˆ‘ä»¬çš„ prompt æ”¹å†™æ¨¡å‹ï¼Œå°†ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯æ”¹å†™ä¸ºæ›´é€‚åˆæ¨¡å‹åå¥½çš„å†™æ³•ã€‚

æˆ‘ä»¬æä¾›äº†ä¸¤ä¸ªæ”¹å†™æ¨¡å¼ï¼šæ­£å¸¸æ¨¡å¼å’Œå¯¼æ¼”æ¨¡å¼ã€‚ä¸¤ç§æ¨¡å¼çš„æç¤ºè¯è§[è¿™é‡Œ](hyvideo/prompt_rewrite.py)ã€‚æ­£å¸¸æ¨¡å¼æ—¨åœ¨å¢å¼ºè§†é¢‘ç”Ÿæˆæ¨¡å‹å¯¹ç”¨æˆ·æ„å›¾çš„ç†è§£ï¼Œä»è€Œæ›´å‡†ç¡®åœ°è§£é‡Šæä¾›çš„æŒ‡ä»¤ã€‚å¯¼æ¼”æ¨¡å¼å¢å¼ºäº†è¯¸å¦‚æ„å›¾ã€å…‰ç…§å’Œæ‘„åƒæœºç§»åŠ¨ç­‰æ–¹é¢çš„æè¿°ï¼Œå€¾å‘äºç”Ÿæˆè§†è§‰è´¨é‡æ›´é«˜çš„è§†é¢‘ã€‚æ³¨æ„ï¼Œè¿™ç§å¢å¼ºæœ‰æ—¶å¯èƒ½ä¼šå¯¼è‡´ä¸€äº›è¯­ä¹‰ç»†èŠ‚çš„ä¸¢å¤±ã€‚

Prompt æ”¹å†™æ¨¡å‹å¯ä»¥ç›´æ¥ä½¿ç”¨ [Hunyuan-Large](https://github.com/Tencent/Tencent-Hunyuan-Large) éƒ¨ç½²å’Œæ¨ç†. æˆ‘ä»¬å¼€æºäº† prompt æ”¹å†™æ¨¡å‹çš„æƒé‡ï¼Œè§[è¿™é‡Œ](https://huggingface.co/Tencent/HunyuanVideo-PromptRewrite).



## ğŸ“ˆ èƒ½åŠ›è¯„ä¼°

ä¸ºäº†è¯„ä¼° HunyuanVideo çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬é€‰æ‹©äº†å››ä¸ªé—­æºè§†é¢‘ç”Ÿæˆæ¨¡å‹ä½œä¸ºå¯¹æ¯”ã€‚æˆ‘ä»¬æ€»å…±ä½¿ç”¨äº† 1,533 ä¸ª promptï¼Œæ¯ä¸ª prompt é€šè¿‡ä¸€æ¬¡æ¨ç†ç”Ÿæˆäº†ç›¸åŒæ•°é‡çš„è§†é¢‘æ ·æœ¬ã€‚ä¸ºäº†å…¬å¹³æ¯”è¾ƒï¼Œæˆ‘ä»¬åªè¿›è¡Œäº†ä¸€æ¬¡æ¨ç†ä»¥é¿å…ä»»ä½•æŒ‘é€‰ã€‚åœ¨ä¸å…¶ä»–æ–¹æ³•æ¯”è¾ƒæ—¶ï¼Œæˆ‘ä»¬ä¿æŒäº†æ‰€æœ‰é€‰æ‹©æ¨¡å‹çš„é»˜è®¤è®¾ç½®ï¼Œå¹¶ç¡®ä¿äº†è§†é¢‘åˆ†è¾¨ç‡çš„ä¸€è‡´æ€§ã€‚è§†é¢‘æ ¹æ®ä¸‰ä¸ªæ ‡å‡†è¿›è¡Œè¯„ä¼°ï¼šæ–‡æœ¬å¯¹é½ã€è¿åŠ¨è´¨é‡å’Œè§†è§‰è´¨é‡ã€‚åœ¨ 60 å¤šåä¸“ä¸šè¯„ä¼°äººå‘˜è¯„ä¼°åï¼ŒHunyuanVideo åœ¨ç»¼åˆæŒ‡æ ‡ä¸Šè¡¨ç°æœ€å¥½ï¼Œç‰¹åˆ«æ˜¯åœ¨è¿åŠ¨è´¨é‡æ–¹é¢è¡¨ç°è¾ƒä¸ºçªå‡ºã€‚

<p align="center">
<table> 
<thead> 
<tr> 
    <th rowspan="2">æ¨¡å‹</th> <th rowspan="2">æ˜¯å¦å¼€æº</th> <th>æ—¶é•¿</th> <th>æ–‡æœ¬å¯¹é½</th> <th>è¿åŠ¨è´¨é‡</th> <th rowspan="2">è§†è§‰è´¨é‡</th> <th rowspan="2">ç»¼åˆè¯„ä»·</th>  <th rowspan="2">æ’åº</th>
</tr> 
</thead> 
<tbody> 
<tr> 
    <td>HunyuanVideo (Ours)</td> <td> âœ” </td> <td>5s</td> <td>61.8%</td> <td>66.5%</td> <td>95.7%</td> <td>41.3%</td> <td>1</td>
</tr> 
<tr> 
    <td>å›½å†…æ¨¡å‹ A (API)</td> <td> &#10008 </td> <td>5s</td> <td>62.6%</td> <td>61.7%</td> <td>95.6%</td> <td>37.7%</td> <td>2</td>
</tr> 
<tr> 
    <td>å›½å†…æ¨¡å‹ B (Web)</td> <td> &#10008</td> <td>5s</td> <td>60.1%</td> <td>62.9%</td> <td>97.7%</td> <td>37.5%</td> <td>3</td>
</tr> 
<tr> 
    <td>GEN-3 alpha (Web)</td> <td>&#10008</td> <td>6s</td> <td>47.7%</td> <td>54.7%</td> <td>97.5%</td> <td>27.4%</td> <td>4</td> 
</tr> 
<tr> 
    <td>Luma1.6 (API)</td><td>&#10008</td> <td>5s</td> <td>57.6%</td> <td>44.2%</td> <td>94.1%</td> <td>24.8%</td> <td>5</td>
</tr>
</tbody>
</table>
</p>


## ğŸ“œ è¿è¡Œé…ç½®

ä¸‹è¡¨åˆ—å‡ºäº†è¿è¡Œ HunyuanVideo æ¨¡å‹ä½¿ç”¨æ–‡æœ¬ç”Ÿæˆè§†é¢‘çš„æ¨èé…ç½®ï¼ˆbatch size = 1ï¼‰ï¼š

|     æ¨¡å‹      | åˆ†è¾¨ç‡<br/>(height/width/frame) | å³°å€¼æ˜¾å­˜  |
|:--------------:|:--------------------------------:|:----------------:|
| HunyuanVideo   |         720px1280px129f          |       60G        |
| HunyuanVideo   |          544px960px129f          |       45G        |

* æœ¬é¡¹ç›®é€‚ç”¨äºä½¿ç”¨ NVIDIA GPU å’Œæ”¯æŒ CUDA çš„è®¾å¤‡
  * æ¨¡å‹åœ¨å•å¼  80G GPU ä¸Šæµ‹è¯•
  * è¿è¡Œ 720px1280px129f çš„æœ€å°æ˜¾å­˜è¦æ±‚æ˜¯ 60GBï¼Œ544px960px129f çš„æœ€å°æ˜¾å­˜è¦æ±‚æ˜¯ 45GBã€‚
* æµ‹è¯•æ“ä½œç³»ç»Ÿï¼šLinux



## ğŸ› ï¸ å®‰è£…å’Œä¾èµ–

é¦–å…ˆå…‹éš† git ä»“åº“:
```shell
git clone https://github.com/tencent/HunyuanVideo
cd HunyuanVideo
```

### Linux å®‰è£…æŒ‡å¼•

æˆ‘ä»¬æ¨èä½¿ç”¨ CUDA 12.4 æˆ– 11.8 çš„ç‰ˆæœ¬ã€‚

Conda çš„å®‰è£…æŒ‡å—å¯ä»¥å‚è€ƒ[è¿™é‡Œ](https://docs.anaconda.com/free/miniconda/index.html)ã€‚

```shell
# 1. Create conda environment
conda create -n HunyuanVideo python==3.10.9

# 2. Activate the environment
conda activate HunyuanVideo

# 3. Install PyTorch and other dependencies using conda
# For CUDA 11.8
conda install pytorch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 pytorch-cuda=11.8 -c pytorch -c nvidia
# For CUDA 12.4
conda install pytorch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 pytorch-cuda=12.4 -c pytorch -c nvidia

# 4. Install pip dependencies
python -m pip install -r requirements.txt

# 5. Install flash attention v2 for acceleration (requires CUDA 11.8 or above)
python -m pip install ninja
python -m pip install git+https://github.com/Dao-AILab/flash-attention.git@v2.6.3

# 6. Install xDiT for parallel inference (It is recommended to use torch 2.4.0 and flash-attn 2.6.3)
python -m pip install xfuser==0.4.0
```

å¦‚æœåœ¨ç‰¹å®š GPU å‹å·ä¸Šé­é‡ float point exception(core dump) é—®é¢˜ï¼Œå¯å°è¯•ä»¥ä¸‹æ–¹æ¡ˆä¿®å¤ï¼š

```shell
#é€‰é¡¹1ï¼šç¡®ä¿å·²æ­£ç¡®å®‰è£… CUDA 12.4, CUBLAS>=12.4.5.8, å’Œ CUDNN>=9.00 (æˆ–ç›´æ¥ä½¿ç”¨æˆ‘ä»¬æä¾›çš„CUDA12é•œåƒ)
pip install nvidia-cublas-cu12==12.4.5.8
export LD_LIBRARY_PATH=/opt/conda/lib/python3.8/site-packages/nvidia/cublas/lib/

#é€‰é¡¹2ï¼šå¼ºåˆ¶æ˜¾å¼ä½¿ç”¨ CUDA11.8 ç¼–è¯‘çš„ Pytorch ç‰ˆæœ¬ä»¥åŠå…¶ä»–æ‰€æœ‰è½¯ä»¶åŒ…
pip uninstall -r requirements.txt  # ç¡®ä¿å¸è½½æ‰€æœ‰ä¾èµ–åŒ…
pip uninstall -y xfuser
pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
pip install ninja
pip install git+https://github.com/Dao-AILab/flash-attention.git@v2.6.3
pip install xfuser==0.4.0
```

å¦å¤–ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªé¢„æ„å»ºçš„ Docker é•œåƒï¼Œå¯ä»¥ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤è¿›è¡Œæ‹‰å–å’Œè¿è¡Œã€‚
```shell
# ç”¨äº CUDA 12.4 (å·²æ›´æ–°é¿å… float point exception)
docker pull hunyuanvideo/hunyuanvideo:cuda_12
docker run -itd --gpus all --init --net=host --uts=host --ipc=host --name hunyuanvideo --security-opt=seccomp=unconfined --ulimit=stack=67108864 --ulimit=memlock=-1 --privileged hunyuanvideo/hunyuanvideo:cuda_12

# ç”¨äº CUDA 11.8
docker pull hunyuanvideo/hunyuanvideo:cuda_11
docker run -itd --gpus all --init --net=host --uts=host --ipc=host --name hunyuanvideo --security-opt=seccomp=unconfined --ulimit=stack=67108864 --ulimit=memlock=-1 --privileged hunyuanvideo/hunyuanvideo:cuda_11
```

## ğŸ§± ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹å‚è€ƒ[è¿™é‡Œ](ckpts/README.md)ã€‚



## ğŸ”‘ å•å¡æ¨ç†

æˆ‘ä»¬åœ¨ä¸‹è¡¨ä¸­åˆ—å‡ºäº†æ”¯æŒçš„é«˜åº¦/å®½åº¦/å¸§æ•°è®¾ç½®ã€‚

|      åˆ†è¾¨ç‡       |           h/w=9:16           |    h/w=16:9     |     h/w=4:3     |     h/w=3:4     |     h/w=1:1     |
|:---------------------:|:----------------------------:|:---------------:|:---------------:|:---------------:|:---------------:|
|         540p          |        544px960px129f        |  960px544px129f | 624px832px129f  |  832px624px129f |  720px720px129f |
| 720p (æ¨è)    |       720px1280px129f        | 1280px720px129f | 1104px832px129f | 832px1104px129f | 960px960px129f  |

### ä½¿ç”¨å‘½ä»¤è¡Œ

```bash
cd HunyuanVideo

python3 sample_video.py \
    --video-size 720 1280 \
    --video-length 129 \
    --infer-steps 50 \
    --prompt "A cat walks on the grass, realistic style." \
    --flow-reverse \
    --use-cpu-offload \
    --save-path ./results
```

### è¿è¡ŒgradioæœåŠ¡
```bash
python3 gradio_server.py --flow-reverse

# set SERVER_NAME and SERVER_PORT manually
# SERVER_NAME=0.0.0.0 SERVER_PORT=8081 python3 gradio_server.py --flow-reverse
```

### æ›´å¤šé…ç½®

ä¸‹é¢åˆ—å‡ºäº†æ›´å¤šå…³é”®é…ç½®é¡¹ï¼š

|        å‚æ•°        |  é»˜è®¤å€¼  |                æè¿°                |
|:----------------------:|:---------:|:-----------------------------------------:|
|       `--prompt`       |   None    |   ç”¨äºç”Ÿæˆè§†é¢‘çš„ prompt    |
|     `--video-size`     | 720 1280  |      ç”Ÿæˆè§†é¢‘çš„é«˜åº¦å’Œå®½åº¦      |
|    `--video-length`    |    129    |     ç”Ÿæˆè§†é¢‘çš„å¸§æ•°     |
|    `--infer-steps`     |    50     |     ç”Ÿæˆæ—¶é‡‡æ ·çš„æ­¥æ•°      |
| `--embedded-cfg-scale` |    6.0    |    æ–‡æœ¬çš„æ§åˆ¶å¼ºåº¦       |
|     `--flow-shift`     |    7.0    | æ¨ç†æ—¶ timestep çš„ shift ç³»æ•°ï¼Œå€¼è¶Šå¤§ï¼Œé«˜å™ªåŒºåŸŸé‡‡æ ·æ­¥æ•°è¶Šå¤š |
|     `--flow-reverse`   |    False  | If reverse, learning/sampling from t=1 -> t=0 |
|     `--neg-prompt`     |   None    | è´Ÿå‘è¯  |
|        `--seed`        |     0     |   éšæœºç§å­    |
|  `--use-cpu-offload`   |   False   |    å¯ç”¨ CPU offloadï¼Œå¯ä»¥èŠ‚çœæ˜¾å­˜    |
|     `--save-path`      | ./results |     ä¿å­˜è·¯å¾„      |



## ğŸš€ ä½¿ç”¨ xDiT å®ç°å¤šå¡å¹¶è¡Œæ¨ç†

[xDiT](https://github.com/xdit-project/xDiT) æ˜¯ä¸€ä¸ªé’ˆå¯¹å¤š GPU é›†ç¾¤çš„æ‰©å±•æ¨ç†å¼•æ“ï¼Œç”¨äºæ‰©å±• Transformersï¼ˆDiTsï¼‰ã€‚
å®ƒæˆåŠŸä¸ºå„ç§ DiT æ¨¡å‹ï¼ˆåŒ…æ‹¬ mochi-1ã€CogVideoXã€Flux.1ã€SD3 ç­‰ï¼‰æä¾›äº†ä½å»¶è¿Ÿçš„å¹¶è¡Œæ¨ç†è§£å†³æ–¹æ¡ˆã€‚è¯¥å­˜å‚¨åº“é‡‡ç”¨äº† [Unified Sequence Parallelism (USP)](https://arxiv.org/abs/2405.07719) API ç”¨äºæ··å…ƒè§†é¢‘æ¨¡å‹çš„å¹¶è¡Œæ¨ç†ã€‚

### ä½¿ç”¨å‘½ä»¤è¡Œ

ä¾‹å¦‚ï¼Œå¯ç”¨å¦‚ä¸‹å‘½ä»¤ä½¿ç”¨8å¼ GPUå¡å®Œæˆæ¨ç†

```bash
cd HunyuanVideo

torchrun --nproc_per_node=8 sample_video_parallel.py \
    --video-size 1280 720 \
    --video-length 129 \
    --infer-steps 50 \
    --prompt "A cat walks on the grass, realistic style." \
    --flow-reverse \
    --seed 42 \
    --ulysses_degree 8 \
    --ring_degree 1 \
    --save-path ./results
```

å¯ä»¥é…ç½®`--ulysses-degree`å’Œ`--ring-degree`æ¥æ§åˆ¶å¹¶è¡Œé…ç½®ï¼Œå¯é€‰å‚æ•°å¦‚ä¸‹ã€‚

<details>
<summary>æ”¯æŒçš„å¹¶è¡Œé…ç½® (ç‚¹å‡»æŸ¥çœ‹è¯¦æƒ…)</summary>

|     --video-size     | --video-length | --ulysses-degree x --ring-degree | --nproc_per_node |
|----------------------|----------------|----------------------------------|------------------|
| 1280 720 æˆ– 720 1280 | 129            | 8x1,4x2,2x4,1x8                  | 8                |
| 1280 720 æˆ– 720 1280 | 129            | 1x5                              | 5                |
| 1280 720 æˆ– 720 1280 | 129            | 4x1,2x2,1x4                      | 4                |
| 1280 720 æˆ– 720 1280 | 129            | 3x1,1x3                          | 3                |
| 1280 720 æˆ– 720 1280 | 129            | 2x1,1x2                          | 2                |
| 1104 832 æˆ– 832 1104 | 129            | 4x1,2x2,1x4                      | 4                |
| 1104 832 æˆ– 832 1104 | 129            | 3x1,1x3                          | 3                |
| 1104 832 æˆ– 832 1104 | 129            | 2x1,1x2                          | 2                |
| 960 960              | 129            | 6x1,3x2,2x3,1x6                  | 6                |
| 960 960              | 129            | 4x1,2x2,1x4                      | 4                |
| 960 960              | 129            | 3x1,1x3                          | 3                |
| 960 960              | 129            | 1x2,2x1                          | 2                |
| 960 544 æˆ– 544 960   | 129            | 6x1,3x2,2x3,1x6                  | 6                |
| 960 544 æˆ– 544 960   | 129            | 4x1,2x2,1x4                      | 4                |
| 960 544 æˆ– 544 960   | 129            | 3x1,1x3                          | 3                |
| 960 544 æˆ– 544 960   | 129            | 1x2,2x1                          | 2                |
| 832 624 æˆ– 624 832   | 129            | 4x1,2x2,1x4                      | 4                |
| 624 832 æˆ– 624 832   | 129            | 3x1,1x3                          | 3                |
| 832 624 æˆ– 624 832   | 129            | 2x1,1x2                          | 2                |
| 720 720              | 129            | 1x5                              | 5                |
| 720 720              | 129            | 3x1,1x3                          | 3                |

</details>

<p align="center">
<table align="center">
<thead>
<tr>
    <th colspan="4">åœ¨ 8xGPUä¸Šç”Ÿæˆ1280x720 (129 å¸§ 50 æ­¥)çš„æ—¶è€— (ç§’)  </th>
</tr>
<tr>
    <th>1</th>
    <th>2</th>
    <th>4</th>
    <th>8</th>
</tr>
</thead>
<tbody>
<tr>
    <th>1904.08</th>
    <th>934.09 (2.04x)</th>
    <th>514.08 (3.70x)</th>
    <th>337.58 (5.64x)</th>
</tr>

</tbody>
</table>
</p>



## ğŸš€   FP8 Inference

ä½¿ç”¨FP8é‡åŒ–åçš„HunyuanVideoæ¨¡å‹èƒ½å¤Ÿå¸®æ‚¨èŠ‚çœå¤§æ¦‚10GBæ˜¾å­˜ã€‚ ä½¿ç”¨å‰éœ€è¦ä» Huggingface ä¸‹è½½[FP8æƒé‡](https://huggingface.co/tencent/HunyuanVideo/blob/main/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8.pt)å’Œæ¯å±‚é‡åŒ–æƒé‡çš„[scaleå‚æ•°](https://huggingface.co/tencent/HunyuanVideo/blob/main/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states_fp8_map.pt).

### Using Command Line

è¿™é‡Œï¼Œæ‚¨å¿…é¡»æ˜¾ç¤ºåœ°æŒ‡å®šFP8çš„æƒé‡è·¯å¾„ã€‚ä¾‹å¦‚ï¼Œå¯ç”¨å¦‚ä¸‹å‘½ä»¤ä½¿ç”¨FP8æ¨¡å‹æ¨ç†

```bash
cd HunyuanVideo

DIT_CKPT_PATH={PATH_TO_FP8_WEIGHTS}/{WEIGHT_NAME}_fp8.pt

python3 sample_video.py \
    --dit-weight ${DIT_CKPT_PATH} \
    --video-size 1280 720 \
    --video-length 129 \
    --infer-steps 50 \
    --prompt "A cat walks on the grass, realistic style." \
    --seed 42 \
    --embedded-cfg-scale 6.0 \
    --flow-shift 7.0 \
    --flow-reverse \
    --use-cpu-offload \
    --use-fp8 \
    --save-path ./results
```



## ğŸ”— BibTeX

å¦‚æœæ‚¨è®¤ä¸º [HunyuanVideo](https://arxiv.org/abs/2412.03603) ç»™æ‚¨çš„ç ”ç©¶å’Œåº”ç”¨å¸¦æ¥äº†ä¸€äº›å¸®åŠ©ï¼Œå¯ä»¥é€šè¿‡ä¸‹é¢çš„æ–¹å¼æ¥å¼•ç”¨:

```BibTeX
@misc{kong2024hunyuanvideo,
      title={HunyuanVideo: A Systematic Framework For Large Video Generative Models}, 
      author={Weijie Kong, Qi Tian, Zijian Zhang, Rox Min, Zuozhuo Dai, Jin Zhou, Jiangfeng Xiong, Xin Li, Bo Wu, Jianwei Zhang, Kathrina Wu, Qin Lin, Aladdin Wang, Andong Wang, Changlin Li, Duojun Huang, Fang Yang, Hao Tan, Hongmei Wang, Jacob Song, Jiawang Bai, Jianbing Wu, Jinbao Xue, Joey Wang, Junkun Yuan, Kai Wang, Mengyang Liu, Pengyu Li, Shuai Li, Weiyan Wang, Wenqing Yu, Xinchi Deng, Yang Li, Yanxin Long, Yi Chen, Yutao Cui, Yuanbo Peng, Zhentao Yu, Zhiyu He, Zhiyong Xu, Zixiang Zhou, Zunnan Xu, Yangyu Tao, Qinglin Lu, Songtao Liu, Dax Zhou, Hongfa Wang, Yong Yang, Di Wang, Yuhong Liu, and Jie Jiang, along with Caesar Zhong},
      year={2024},
      archivePrefix={arXiv preprint arXiv:2412.03603},
      primaryClass={cs.CV}
}
```



## è‡´è°¢

HunyuanVideo çš„å¼€æºç¦»ä¸å¼€è¯¸å¤šå¼€æºå·¥ä½œï¼Œè¿™é‡Œæˆ‘ä»¬ç‰¹åˆ«æ„Ÿè°¢ [SD3](https://huggingface.co/stabilityai/stable-diffusion-3-medium), [FLUX](https://github.com/black-forest-labs/flux), [Llama](https://github.com/meta-llama/llama), [LLaVA](https://github.com/haotian-liu/LLaVA), [Xtuner](https://github.com/InternLM/xtuner), [diffusers](https://github.com/huggingface/diffusers) and [HuggingFace](https://huggingface.co) çš„å¼€æºå·¥ä½œå’Œæ¢ç´¢ã€‚å¦å¤–ï¼Œæˆ‘ä»¬ä¹Ÿæ„Ÿè°¢è…¾è®¯æ··å…ƒå¤šæ¨¡æ€å›¢é˜Ÿå¯¹ HunyuanVideo é€‚é…å¤šç§æ–‡æœ¬ç¼–ç å™¨çš„æ”¯æŒã€‚



## Star è¶‹åŠ¿

<a href="https://star-history.com/#Tencent/HunyuanVideo&Date">
 <picture>
   <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=Tencent/HunyuanVideo&type=Date&theme=dark" />
   <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=Tencent/HunyuanVideo&type=Date" />
   <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=Tencent/HunyuanVideo&type=Date" />
 </picture>
</a>
